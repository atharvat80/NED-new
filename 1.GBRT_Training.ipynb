{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GBRT data files...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from src.GBRT import GBRT\n",
    "from src.GBRT.utils import *\n",
    "from src.utils import cos_sim, get_document\n",
    "from tqdm import tqdm\n",
    "\n",
    "EMB_PATH = \"C:\\\\Personal Files\\\\NED-using-KG\\\\embeddings\\\\wiki2vec_w10_100d.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, fname):\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1162/1162 [03:03<00:00,  6.34it/s]\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "gbrt = GBRT(EMB_PATH)\n",
    "for i in tqdm(range(1, 1163)):\n",
    "    data = pd.read_csv(f'./data/aida/candidates/{i}.csv')\n",
    "    mentions = data['mention'].unique()\n",
    "    candidates = data['candidate'].unique()\n",
    "    max_prob = get_max_prior_prob(mentions, candidates)\n",
    "    \n",
    "    # Base features\n",
    "    data['priorProb'] = [get_prior_prob(i[1], i[2])\n",
    "                         for i in data[['candidate', 'mention']].itertuples()]\n",
    "    data['entityPrior'] = data['candidate'].map(get_entity_prior)\n",
    "    data['maxPriorProb'] = data['candidate'].map(max_prob)\n",
    "    \n",
    "    # String similarity features\n",
    "    ment_normalised = data['mention'].map(lambda x: x.lower())\n",
    "    cand_normalised = data['candidate'].map(lambda x: x.lower().replace('_', ' '))\n",
    "    ment_cand = list(zip(ment_normalised, cand_normalised))\n",
    "    data['editDist'] = [get_edit_dist(m, c) for m, c in ment_cand]\n",
    "    data['mentionIsCand'] = [m == c for m, c in ment_cand]\n",
    "    data['mentionInCand'] = [m in c for m, c in ment_cand]\n",
    "    data['isStartorEnd'] = [c.startswith(m) or c.endswith(m) for m, c in ment_cand]\n",
    "\n",
    "    # Context based features\n",
    "    # Context similarity \n",
    "    context_emb = gbrt.encode_sentence(get_document(i))\n",
    "    data['contextSim'] = data['candidate'].map(\n",
    "        lambda x: cos_sim(gbrt.encode_entity(x), context_emb))\n",
    "    # Coherence score\n",
    "    unamb_entities = data[data['priorProb'] >= 0.95]['candidate'].unique()\n",
    "    context_ent_emb = gbrt.encode_context_entities(unamb_entities)\n",
    "    data['coherence'] = data['candidate'].map(\n",
    "        lambda x: cos_sim(gbrt.encode_entity(x), context_ent_emb))\n",
    "    # Add rank\n",
    "    # data = rank_values(data)\n",
    "\n",
    "    # Add ground truth\n",
    "    data['y'] = (data['candidate'] == data['tag']).map(int)\n",
    "    dfs.append(data)\n",
    "\n",
    "X = pd.concat(dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15593\n"
     ]
    }
   ],
   "source": [
    "#  add rank\n",
    "dfs = []\n",
    "while X.shape[0] != 0:\n",
    "    n = X.iloc[0]['numCands']\n",
    "    temp = X.head(n).copy()\n",
    "    temp['score'] = temp.contextSim\t+ temp.coherence\n",
    "    temp = temp.sort_values(by=['score'], ascending=False).reset_index(drop=True)\n",
    "    temp['rank'] = temp.index + 1\n",
    "    X = X.iloc[n:]\n",
    "    dfs.append(temp)\n",
    "\n",
    "print(len(dfs))\n",
    "X = pd.concat(dfs).reset_index(drop=True)\n",
    "X.to_csv('./data/GBRT/train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the GBRT Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>tag</th>\n",
       "      <th>candidate</th>\n",
       "      <th>numCands</th>\n",
       "      <th>priorProb</th>\n",
       "      <th>entityPrior</th>\n",
       "      <th>maxPriorProb</th>\n",
       "      <th>editDist</th>\n",
       "      <th>mentionIsCand</th>\n",
       "      <th>mentionInCand</th>\n",
       "      <th>isStartorEnd</th>\n",
       "      <th>contextSim</th>\n",
       "      <th>coherence</th>\n",
       "      <th>y</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German</td>\n",
       "      <td>Germany</td>\n",
       "      <td>German_model</td>\n",
       "      <td>39</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.670730e-06</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.488999</td>\n",
       "      <td>0.564448</td>\n",
       "      <td>0</td>\n",
       "      <td>1.053448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German</td>\n",
       "      <td>Germany</td>\n",
       "      <td>German_Party_(1961)</td>\n",
       "      <td>39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.475156e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.482056</td>\n",
       "      <td>0.497495</td>\n",
       "      <td>0</td>\n",
       "      <td>0.979551</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German</td>\n",
       "      <td>Germany</td>\n",
       "      <td>German_Party_(1947)</td>\n",
       "      <td>39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.970187e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.406279</td>\n",
       "      <td>0.480351</td>\n",
       "      <td>0</td>\n",
       "      <td>0.886631</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>German</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Elections_in_Germany</td>\n",
       "      <td>39</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>1.212826e-05</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.402251</td>\n",
       "      <td>0.447347</td>\n",
       "      <td>0</td>\n",
       "      <td>0.849598</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>German</td>\n",
       "      <td>Germany</td>\n",
       "      <td>German-speaking_Community_of_Belgium</td>\n",
       "      <td>39</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>5.135948e-06</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.378138</td>\n",
       "      <td>0.466869</td>\n",
       "      <td>0</td>\n",
       "      <td>0.845007</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193250</th>\n",
       "      <td>DHAKA</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>Dhaka_(village)</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.187889e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193251</th>\n",
       "      <td>DHAKA</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>Dhaka_Regency</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193252</th>\n",
       "      <td>DHAKA</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>Dhaka,_East_Champaran</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>1.051941e-06</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193253</th>\n",
       "      <td>Dhaka Stock Exchange</td>\n",
       "      <td>Dhaka_Stock_Exchange</td>\n",
       "      <td>Dhaka_Stock_Exchange</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.670730e-06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.662831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.662831</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193254</th>\n",
       "      <td>Moslem</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Islam</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>5.593852e-05</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363010</td>\n",
       "      <td>0.348749</td>\n",
       "      <td>1</td>\n",
       "      <td>0.711759</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193255 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mention                   tag  \\\n",
       "0                     German               Germany   \n",
       "1                     German               Germany   \n",
       "2                     German               Germany   \n",
       "3                     German               Germany   \n",
       "4                     German               Germany   \n",
       "...                      ...                   ...   \n",
       "193250                 DHAKA                 Dhaka   \n",
       "193251                 DHAKA                 Dhaka   \n",
       "193252                 DHAKA                 Dhaka   \n",
       "193253  Dhaka Stock Exchange  Dhaka_Stock_Exchange   \n",
       "193254                Moslem                 Islam   \n",
       "\n",
       "                                   candidate  numCands  priorProb  \\\n",
       "0                               German_model        39   0.000016   \n",
       "1                        German_Party_(1961)        39   0.000000   \n",
       "2                        German_Party_(1947)        39   0.000000   \n",
       "3                       Elections_in_Germany        39   0.000032   \n",
       "4       German-speaking_Community_of_Belgium        39   0.000047   \n",
       "...                                      ...       ...        ...   \n",
       "193250                       Dhaka_(village)        11   0.000000   \n",
       "193251                         Dhaka_Regency        11   0.000000   \n",
       "193252                 Dhaka,_East_Champaran        11   0.000230   \n",
       "193253                  Dhaka_Stock_Exchange         1   1.000000   \n",
       "193254                                 Islam         1   0.033898   \n",
       "\n",
       "         entityPrior  maxPriorProb  editDist  mentionIsCand  mentionInCand  \\\n",
       "0       1.670730e-06      0.000016       6.0            0.0            1.0   \n",
       "1       2.475156e-07      0.000000      13.0            0.0            1.0   \n",
       "2       2.970187e-06      0.000000      13.0            0.0            1.0   \n",
       "3       1.212826e-05      0.000776      14.0            0.0            1.0   \n",
       "4       5.135948e-06      0.000047      30.0            0.0            1.0   \n",
       "...              ...           ...       ...            ...            ...   \n",
       "193250  6.187889e-08      0.000000      10.0            0.0            1.0   \n",
       "193251  0.000000e+00      0.000000       8.0            0.0            1.0   \n",
       "193252  1.051941e-06      0.000230      16.0            0.0            1.0   \n",
       "193253  1.670730e-06      1.000000       0.0            1.0            1.0   \n",
       "193254  5.593852e-05      0.033898       3.0            0.0            0.0   \n",
       "\n",
       "        isStartorEnd  contextSim  coherence  y     score  rank  \n",
       "0                1.0    0.488999   0.564448  0  1.053448     1  \n",
       "1                1.0    0.482056   0.497495  0  0.979551     2  \n",
       "2                1.0    0.406279   0.480351  0  0.886631     3  \n",
       "3                0.0    0.402251   0.447347  0  0.849598     4  \n",
       "4                1.0    0.378138   0.466869  0  0.845007     5  \n",
       "...              ...         ...        ... ..       ...   ...  \n",
       "193250           1.0    0.000000   0.000000  0  0.000000     9  \n",
       "193251           1.0    0.000000   0.000000  0  0.000000    10  \n",
       "193252           1.0    0.000000   0.000000  0  0.000000    11  \n",
       "193253           1.0    0.662831   1.000000  1  1.662831     1  \n",
       "193254           0.0    0.363010   0.348749  1  0.711759     1  \n",
       "\n",
       "[193255 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv('./data/GBRT/train.csv')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.drop(columns=['mention', 'candidate', 'tag', 'y'])\n",
    "y_train = X['y'].to_numpy()\n",
    "\n",
    "BASE = ['priorProb', 'entityPrior', 'maxPriorProb', 'numCands']\n",
    "STRING_SIM = BASE + ['editDist', 'mentionIsCand', 'mentionInCand', 'isStartorEnd']\n",
    "CONTEXT = STRING_SIM + ['contextSim']\n",
    "ALL = CONTEXT + ['coherence', 'rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0722           32.34m\n",
      "         2           0.0703           38.52m\n",
      "         3           0.0685           38.56m\n",
      "         4           0.0668           34.81m\n",
      "         5           0.0651           34.32m\n",
      "         6           0.0635           32.17m\n",
      "         7           0.0619           31.02m\n",
      "         8           0.0604           29.80m\n",
      "         9           0.0590           29.27m\n",
      "        10           0.0577           28.22m\n",
      "        20           0.0466           25.14m\n",
      "        30           0.0391           23.86m\n",
      "        40           0.0341           23.46m\n",
      "        50           0.0306           22.98m\n",
      "        60           0.0283           22.71m\n",
      "        70           0.0267           22.62m\n",
      "        80           0.0255           22.56m\n",
      "        90           0.0247           22.59m\n",
      "       100           0.0241           22.55m\n",
      "       200           0.0219           21.92m\n",
      "       300           0.0212           21.32m\n",
      "       400           0.0206           21.41m\n",
      "       500           0.0201           21.09m\n",
      "       600           0.0197           21.19m\n",
      "       700           0.0193           22.41m\n",
      "       800           0.0189           22.32m\n",
      "       900           0.0186           22.08m\n",
      "      1000           0.0182           21.78m\n",
      "      2000           0.0156           19.42m\n",
      "      3000           0.0139           18.36m\n",
      "      4000           0.0126           17.18m\n",
      "      5000           0.0116           14.43m\n",
      "      6000           0.0108           11.23m\n",
      "      7000           0.0101            8.46m\n",
      "      8000           0.0096            6.10m\n",
      "      9000           0.0091            3.28m\n",
      "     10000           0.0087            0.00s\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(n_estimators=10000, learning_rate=0.02,\n",
    "                                  max_depth=4, random_state=0, verbose=True)\n",
    "model.fit(X_train[BASE].to_numpy(), y_train)\n",
    "save_model(model, './data/GBRT/base.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0721           68.50m\n",
      "         2           0.0702           66.63m\n",
      "         3           0.0683           66.29m\n",
      "         4           0.0665           58.52m\n",
      "         5           0.0648           54.82m\n",
      "         6           0.0632           51.67m\n",
      "         7           0.0616           50.20m\n",
      "         8           0.0600           51.28m\n",
      "         9           0.0586           53.12m\n",
      "        10           0.0572           53.54m\n",
      "        20           0.0457           48.20m\n",
      "        30           0.0380           49.75m\n",
      "        40           0.0328           55.90m\n",
      "        50           0.0292           58.30m\n",
      "        60           0.0268           54.45m\n",
      "        70           0.0251           51.37m\n",
      "        80           0.0239           49.12m\n",
      "        90           0.0230           47.34m\n",
      "       100           0.0224           46.92m\n",
      "       200           0.0200           50.82m\n",
      "       300           0.0192           56.08m\n",
      "       400           0.0186           58.17m\n",
      "       500           0.0181           60.22m\n",
      "       600           0.0176           60.81m\n",
      "       700           0.0171           60.64m\n",
      "       800           0.0167           60.47m\n",
      "       900           0.0164           59.92m\n",
      "      1000           0.0160           59.70m\n",
      "      2000           0.0138           50.94m\n",
      "      3000           0.0125           41.44m\n",
      "      4000           0.0114           35.15m\n",
      "      5000           0.0106           26.14m\n",
      "      6000           0.0099           19.75m\n",
      "      7000           0.0093           14.34m\n",
      "      8000           0.0088            9.25m\n",
      "      9000           0.0084            4.55m\n",
      "     10000           0.0081            0.00s\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(n_estimators=10000, learning_rate=0.02,\n",
    "                                  max_depth=4, random_state=0, verbose=True)\n",
    "model.fit(X_train[STRING_SIM].to_numpy(), y_train)\n",
    "save_model(model, './data/GBRT/string_sim.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0721           94.83m\n",
      "         2           0.0700           81.23m\n",
      "         3           0.0681           74.16m\n",
      "         4           0.0662           69.78m\n",
      "         5           0.0644           65.94m\n",
      "         6           0.0627           63.90m\n",
      "         7           0.0610           62.46m\n",
      "         8           0.0594           61.69m\n",
      "         9           0.0579           60.47m\n",
      "        10           0.0564           62.53m\n",
      "        20           0.0443           80.70m\n",
      "        30           0.0362           75.52m\n",
      "        40           0.0305           70.53m\n",
      "        50           0.0266           67.50m\n",
      "        60           0.0239           65.25m\n",
      "        70           0.0219           64.24m\n",
      "        80           0.0205           62.45m\n",
      "        90           0.0194           61.09m\n",
      "       100           0.0186           59.92m\n",
      "       200           0.0159           55.21m\n",
      "       300           0.0151           58.18m\n",
      "       400           0.0144           57.30m\n",
      "       500           0.0139           55.03m\n",
      "       600           0.0135           53.16m\n",
      "       700           0.0132           51.71m\n",
      "       800           0.0129           50.50m\n",
      "       900           0.0126           49.82m\n",
      "      1000           0.0124           49.54m\n",
      "      2000           0.0107           43.95m\n",
      "      3000           0.0096           36.02m\n",
      "      4000           0.0088           30.50m\n",
      "      5000           0.0082           25.42m\n",
      "      6000           0.0076           20.23m\n",
      "      7000           0.0070           15.25m\n",
      "      8000           0.0066           10.20m\n",
      "      9000           0.0062            5.10m\n",
      "     10000           0.0059            0.00s\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(n_estimators=10000, learning_rate=0.02,\n",
    "                                  max_depth=4, random_state=0, verbose=True)\n",
    "model.fit(X_train[CONTEXT].to_numpy(), y_train)\n",
    "save_model(model, './data/GBRT/context.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0720           75.00m\n",
      "         2           0.0700           71.95m\n",
      "         3           0.0680           72.45m\n",
      "         4           0.0661           72.99m\n",
      "         5           0.0642           72.82m\n",
      "         6           0.0625           72.34m\n",
      "         7           0.0608           79.44m\n",
      "         8           0.0591           83.37m\n",
      "         9           0.0576           89.38m\n",
      "        10           0.0561           89.12m\n",
      "        20           0.0437           79.82m\n",
      "        30           0.0353           75.02m\n",
      "        40           0.0294           73.22m\n",
      "        50           0.0252           72.47m\n",
      "        60           0.0223           71.00m\n",
      "        70           0.0203           69.54m\n",
      "        80           0.0188           69.17m\n",
      "        90           0.0176           68.70m\n",
      "       100           0.0168           68.25m\n",
      "       200           0.0140           70.66m\n",
      "       300           0.0131           71.92m\n",
      "       400           0.0126           72.01m\n",
      "       500           0.0123           69.96m\n",
      "       600           0.0119           69.71m\n",
      "       700           0.0117           70.35m\n",
      "       800           0.0114           71.96m\n",
      "       900           0.0112           73.02m\n",
      "      1000           0.0110           76.06m\n",
      "      2000           0.0095           72.61m\n",
      "      3000           0.0085           61.20m\n",
      "      4000           0.0078           50.93m\n",
      "      5000           0.0072           40.85m\n",
      "      6000           0.0067           31.54m\n",
      "      7000           0.0062           23.35m\n",
      "      8000           0.0058           15.20m\n",
      "      9000           0.0054            7.53m\n",
      "     10000           0.0051            0.00s\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(n_estimators=10000, learning_rate=0.02,\n",
    "                                  max_depth=4, random_state=0, verbose=True)\n",
    "model.fit(X_train[ALL[:-1]].to_numpy(), y_train)\n",
    "save_model(model, './data/GBRT/coherence_no_rank.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0719           79.34m\n",
      "         2           0.0698           76.72m\n",
      "         3           0.0677           74.20m\n",
      "         4           0.0657           77.34m\n",
      "         5           0.0638           75.44m\n",
      "         6           0.0620           75.22m\n",
      "         7           0.0603           74.88m\n",
      "         8           0.0585           74.24m\n",
      "         9           0.0569           73.34m\n",
      "        10           0.0553           72.65m\n",
      "        20           0.0425           72.89m\n",
      "        30           0.0336           78.51m\n",
      "        40           0.0276           76.61m\n",
      "        50           0.0233           74.65m\n",
      "        60           0.0203           73.22m\n",
      "        70           0.0182           72.05m\n",
      "        80           0.0167           71.05m\n",
      "        90           0.0156           70.24m\n",
      "       100           0.0149           69.63m\n",
      "       200           0.0122           65.90m\n",
      "       300           0.0115           64.23m\n",
      "       400           0.0110           63.43m\n",
      "       500           0.0107           63.25m\n",
      "       600           0.0105           63.21m\n",
      "       700           0.0102           62.18m\n",
      "       800           0.0100           61.10m\n",
      "       900           0.0098           58.83m\n",
      "      1000           0.0096           56.92m\n",
      "      2000           0.0084           50.79m\n",
      "      3000           0.0076           60.77m\n",
      "      4000           0.0069           58.48m\n",
      "      5000           0.0064           52.55m\n",
      "      6000           0.0060           43.84m\n",
      "      7000           0.0056           32.06m\n",
      "      8000           0.0052           21.38m\n",
      "      9000           0.0048           10.78m\n",
      "     10000           0.0046            0.00s\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(n_estimators=10000, learning_rate=0.02,\n",
    "                                  max_depth=4, random_state=0, verbose=True)\n",
    "model.fit(X_train[ALL].to_numpy(), y_train)\n",
    "save_model(model, './data/GBRT/coherence.pkl')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3c83394ae731fac5cbf34b5abe7ebcd59fb96b846f104eed2689aeb9dd8ae81"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('NED-using-KG': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
