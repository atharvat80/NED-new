{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from wikipedia2vec import Wikipedia2Vec\n",
    "\n",
    "from src.models.GBRT import GBRT\n",
    "from src.utils import aida\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_PATH = \"C:\\\\Personal Files\\\\NED-using-KG\\\\embeddings\\\\\"\n",
    "wiki2vec = Wikipedia2Vec.load(EMB_PATH + 'wiki2vec_w10_100d.pkl')\n",
    "gbrt = GBRT(wiki2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = ['entPrior', 'priorProb', 'maxPriorProb', 'numCands']\n",
    "STRING_SIM = ['editDist', 'mentionIsTitle', 'mentionInTitle', 'mentionIsStartOrEnd']\n",
    "CONTEXT = ['contextSim', 'coherence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, fname):\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "\n",
    "def load_model(fname):\n",
    "    model = None\n",
    "    with open(fname, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_tag(x, tags):\n",
    "    try:\n",
    "        return tags[x].replace('_', ' ')\n",
    "    except:\n",
    "        return 'NIL'\n",
    "\n",
    "\n",
    "def get_feature_data(doc):\n",
    "    cols = ['mention', 'cand'] + BASE + STRING_SIM + ['contextSim']\n",
    "    mentions_cands = aida.get_mentions_cands(doc)\n",
    "    text = aida.get_document(doc)\n",
    "    tags = aida.get_mentions_tags(doc)\n",
    "    X = pd.DataFrame(gbrt.rank(mentions_cands, text), columns=cols)\n",
    "    X['isTag'] = [get_tag(i[1], tags) == i[2] for i in X.itertuples()]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([get_feature_data(i)\n",
    "                     for i in range(1, 1163)]).reset_index(drop=True)\n",
    "X_train.to_csv('./data/GBRT/train_context_sim.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>cand</th>\n",
       "      <th>entPrior</th>\n",
       "      <th>priorProb</th>\n",
       "      <th>maxPriorProb</th>\n",
       "      <th>numCands</th>\n",
       "      <th>editDist</th>\n",
       "      <th>mentionIsTitle</th>\n",
       "      <th>mentionInTitle</th>\n",
       "      <th>mentionIsStartOrEnd</th>\n",
       "      <th>contextSim</th>\n",
       "      <th>isTag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EU</td>\n",
       "      <td>Euthanasia device</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.402096</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EU</td>\n",
       "      <td>European emission standards</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.436891</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EU</td>\n",
       "      <td>European Council</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.490008</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EU</td>\n",
       "      <td>Eu, Seine-Maritime</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.017324</td>\n",
       "      <td>0.017324</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.315598</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EU</td>\n",
       "      <td>.eu</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.374454</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mention                         cand  entPrior  priorProb  maxPriorProb  \\\n",
       "0      EU            Euthanasia device  0.000004   0.000000      0.000000   \n",
       "1      EU  European emission standards  0.000004   0.000241      0.000241   \n",
       "2      EU             European Council  0.000006   0.000481      0.000481   \n",
       "3      EU           Eu, Seine-Maritime  0.000003   0.017324      0.017324   \n",
       "4      EU                          .eu  0.000004   0.000962      0.000962   \n",
       "\n",
       "   numCands  editDist  mentionIsTitle  mentionInTitle  mentionIsStartOrEnd  \\\n",
       "0        18        16           False           False                False   \n",
       "1        18        26           False           False                False   \n",
       "2        18        14           False           False                False   \n",
       "3        18        17           False           False                False   \n",
       "4        18         1           False           False                 True   \n",
       "\n",
       "   contextSim  isTag  \n",
       "0    0.402096  False  \n",
       "1    0.436891  False  \n",
       "2    0.490008  False  \n",
       "3    0.315598  False  \n",
       "4    0.374454  False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv('./data/GBRT/train_context_sim.csv')\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5047           61.80m\n",
      "         2           0.4839           59.98m\n",
      "         3           0.4663           65.27m\n",
      "         4           0.4510           62.22m\n",
      "         5           0.4373           60.57m\n",
      "         6           0.4251           61.19m\n",
      "         7           0.4139           59.18m\n",
      "         8           0.4038           59.03m\n",
      "         9           0.3942           58.75m\n",
      "        10           0.3854           58.47m\n",
      "        20           0.3207           52.96m\n",
      "        30           0.2756           51.15m\n",
      "        40           0.2440           50.10m\n",
      "        50           0.2212           49.47m\n",
      "        60           0.2035           49.06m\n",
      "        70           0.1899           48.69m\n",
      "        80           0.1790           48.69m\n",
      "        90           0.1696           48.85m\n",
      "       100           0.1626           49.01m\n",
      "       200           0.1339           48.94m\n",
      "       300           0.1247           48.70m\n",
      "       400           0.1200           48.56m\n",
      "       500           0.1169           48.51m\n",
      "       600           0.1141           48.09m\n",
      "       700           0.1118           47.69m\n",
      "       800           0.1099           47.30m\n",
      "       900           0.1079           46.92m\n",
      "      1000           0.1062           46.53m\n",
      "      2000           0.0931           42.22m\n",
      "      3000           0.0843           35.80m\n",
      "      4000           0.0772           30.06m\n",
      "      5000           0.0719           24.80m\n",
      "      6000           0.0672           19.69m\n",
      "      7000           0.0627           14.84m\n",
      "      8000           0.0587            9.93m\n",
      "      9000           0.0551            4.95m\n",
      "     10000           0.0519            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.02, max_depth=4, n_estimators=10000,\n",
       "                           verbose=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(n_estimators=10000, max_depth=4,\n",
    "                                   learning_rate=0.02, verbose=True)\n",
    "model.fit(X_train[BASE + STRING_SIM + ['contextSim']], X_train['isTag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, './data/GBRT/context_sim.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>cand</th>\n",
       "      <th>entPrior</th>\n",
       "      <th>priorProb</th>\n",
       "      <th>maxPriorProb</th>\n",
       "      <th>numCands</th>\n",
       "      <th>editDist</th>\n",
       "      <th>mentionIsTitle</th>\n",
       "      <th>mentionInTitle</th>\n",
       "      <th>mentionIsStartOrEnd</th>\n",
       "      <th>contextSim</th>\n",
       "      <th>isTag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JAPAN</td>\n",
       "      <td>Japan national football team</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.014707</td>\n",
       "      <td>0.014707</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.621944</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHINA</td>\n",
       "      <td>China national football team</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.010404</td>\n",
       "      <td>0.010404</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.594390</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL-AIN</td>\n",
       "      <td>Al Ain</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.422713</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.872860</td>\n",
       "      <td>0.872860</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.430725</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Japan national football team</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.014707</td>\n",
       "      <td>0.014707</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.621944</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mention                          cand  entPrior  priorProb  \\\n",
       "0                 JAPAN  Japan national football team  0.000052   0.014707   \n",
       "1                 CHINA  China national football team  0.000026   0.010404   \n",
       "2                AL-AIN                        Al Ain  0.000012   0.005900   \n",
       "3  United Arab Emirates          United Arab Emirates  0.000040   0.872860   \n",
       "4                 Japan  Japan national football team  0.000052   0.014707   \n",
       "\n",
       "   maxPriorProb  numCands  editDist  mentionIsTitle  mentionInTitle  \\\n",
       "0      0.014707        28        24           False           False   \n",
       "1      0.010404        31        24           False           False   \n",
       "2      0.005900         4         3           False           False   \n",
       "3      0.872860         3         3           False            True   \n",
       "4      0.014707        28        24           False            True   \n",
       "\n",
       "   mentionIsStartOrEnd  contextSim  isTag  \n",
       "0                False    0.621944   True  \n",
       "1                False    0.594390   True  \n",
       "2                False    0.422713   True  \n",
       "3                False    0.430725   True  \n",
       "4                False    0.621944   True  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature data for all mentions in test set\n",
    "X_test = [get_feature_data(i) for i in range(1163, 1394)]\n",
    "X_test = pd.concat([i for i in X_test if i.shape[0] > 0]).reset_index(drop=True)\n",
    "# Only keep instances where candidate is the tag as these are the only\n",
    "# instances we need to check if they get classified correctly.\n",
    "X_test_true = X_test[X_test['isTag'] == True].drop_duplicates()\n",
    "X_test_true.reset_index(drop=True, inplace=True)\n",
    "X_test_true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8481569157930334\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_true[BASE + STRING_SIM + ['contextSim']])\n",
    "print(accuracy_score(X_test_true['isTag'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "| Model | Accuracy |\n",
    "| ----------- | ----------- |\n",
    "| Base | 0.7533368926855313 |\n",
    "| Base + String Similarity | 0.7618793379604912 |\n",
    "| Base + String Similarity + Context Similarity | 0.8481569157930334 |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
