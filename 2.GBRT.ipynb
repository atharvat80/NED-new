{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading AIDA dataset...\n",
      "2021-12-16 01:26:08,111 Reading data from C:\\Users\\athar\\.flair\\datasets\\nel_english_aida\n",
      "2021-12-16 01:26:08,132 Train: C:\\Users\\athar\\.flair\\datasets\\nel_english_aida\\train\n",
      "2021-12-16 01:26:08,134 Dev: C:\\Users\\athar\\.flair\\datasets\\nel_english_aida\\testa\n",
      "2021-12-16 01:26:08,135 Test: C:\\Users\\athar\\.flair\\datasets\\nel_english_aida\\testb\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from tqdm import tqdm\n",
    "from wikipedia2vec import Wikipedia2Vec\n",
    "from src.models.GBRT import GBRT\n",
    "from src.utils.GBRT import *\n",
    "from src.utils import aida, cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_PATH = \"C:\\\\Personal Files\\\\NED-using-KG\\\\embeddings\\\\\"\n",
    "wiki2vec = Wikipedia2Vec.load(EMB_PATH + 'wiki2vec_w10_100d.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training data with base features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_candidates(df, mention, tag):\n",
    "    return df[(df['mention'] == mention) & (df['tag'] == tag)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_values(df):\n",
    "    dfs = []\n",
    "    mentions_tags = set([(i[1], i[3]) for i in df.itertuples()])\n",
    "    for mention, tag in mentions_tags:\n",
    "        mention_cands = df[(df['mention'] == mention) & (df['tag'] == tag)].copy()\n",
    "        scores = [(i[2], i[-4] + i[-3]) for i in mention_cands.itertuples()]\n",
    "        scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        rank = {x:i+1 for i, (x, _) in enumerate(scores)}\n",
    "        mention_cands['rank'] = mention_cands['candidate'].map(rank)\n",
    "        dfs.append(mention_cands)\n",
    "    return pd.concat(dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1162/1162 [06:26<00:00,  3.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>candidate</th>\n",
       "      <th>tag</th>\n",
       "      <th>priorProb</th>\n",
       "      <th>entityPrior</th>\n",
       "      <th>maxPriorProb</th>\n",
       "      <th>numCands</th>\n",
       "      <th>editDist</th>\n",
       "      <th>mentionIsCand</th>\n",
       "      <th>mentionInCand</th>\n",
       "      <th>isStartorEnd</th>\n",
       "      <th>contextSim</th>\n",
       "      <th>coherence</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0.400293</td>\n",
       "      <td>4.869869e-05</td>\n",
       "      <td>0.841985</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.290902</td>\n",
       "      <td>0.301004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German</td>\n",
       "      <td>German_Township,_Indiana</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.093945e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German</td>\n",
       "      <td>German_Party_(Yugoslavia)</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.331523e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>German</td>\n",
       "      <td>German_Township,_Ohio</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.093945e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.303123</td>\n",
       "      <td>0.123518</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>German</td>\n",
       "      <td>German-speaking_Community_of_Belgium</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>5.135948e-06</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.378137</td>\n",
       "      <td>0.466869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194600</th>\n",
       "      <td>DHAKA</td>\n",
       "      <td>Dhaka,_East_Champaran</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>1.051941e-06</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194601</th>\n",
       "      <td>DHAKA</td>\n",
       "      <td>Dhaka_Division</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>0.018363</td>\n",
       "      <td>3.032066e-06</td>\n",
       "      <td>0.018363</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.460718</td>\n",
       "      <td>0.663502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194602</th>\n",
       "      <td>DHAKA</td>\n",
       "      <td>Old_Dhaka</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>7.425467e-06</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.439179</td>\n",
       "      <td>0.606731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194603</th>\n",
       "      <td>Dhaka Stock Exchange</td>\n",
       "      <td>Dhaka_Stock_Exchange</td>\n",
       "      <td>Dhaka_Stock_Exchange</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.670730e-06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.662831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194604</th>\n",
       "      <td>Moslem</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Islam</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>5.593852e-05</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.363010</td>\n",
       "      <td>0.348749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194605 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mention                             candidate  \\\n",
       "0                     German                               Germany   \n",
       "1                     German              German_Township,_Indiana   \n",
       "2                     German             German_Party_(Yugoslavia)   \n",
       "3                     German                 German_Township,_Ohio   \n",
       "4                     German  German-speaking_Community_of_Belgium   \n",
       "...                      ...                                   ...   \n",
       "194600                 DHAKA                 Dhaka,_East_Champaran   \n",
       "194601                 DHAKA                        Dhaka_Division   \n",
       "194602                 DHAKA                             Old_Dhaka   \n",
       "194603  Dhaka Stock Exchange                  Dhaka_Stock_Exchange   \n",
       "194604                Moslem                                 Islam   \n",
       "\n",
       "                         tag  priorProb   entityPrior  maxPriorProb  numCands  \\\n",
       "0                    Germany   0.400293  4.869869e-05      0.841985        39   \n",
       "1                    Germany   0.000000  3.093945e-07      0.000000        39   \n",
       "2                    Germany   0.000000  4.331523e-07      0.000000        39   \n",
       "3                    Germany   0.000000  3.093945e-07      0.000000        39   \n",
       "4                    Germany   0.000047  5.135948e-06      0.000047        39   \n",
       "...                      ...        ...           ...           ...       ...   \n",
       "194600                 Dhaka   0.000230  1.051941e-06      0.000230        11   \n",
       "194601                 Dhaka   0.018363  3.032066e-06      0.018363        11   \n",
       "194602                 Dhaka   0.000230  7.425467e-06      0.000230        11   \n",
       "194603  Dhaka_Stock_Exchange   1.000000  1.670730e-06      1.000000         1   \n",
       "194604                 Islam   0.033898  5.593852e-05      0.033898         1   \n",
       "\n",
       "        editDist  mentionIsCand  mentionInCand  isStartorEnd  contextSim  \\\n",
       "0              1          False           True          True    0.290902   \n",
       "1             18          False           True          True    0.000000   \n",
       "2             19          False           True          True    0.000000   \n",
       "3             15          False           True          True    0.303123   \n",
       "4             30          False           True          True    0.378137   \n",
       "...          ...            ...            ...           ...         ...   \n",
       "194600        16          False           True          True    0.000000   \n",
       "194601         9          False           True          True    0.460718   \n",
       "194602         4          False           True          True    0.439179   \n",
       "194603         0           True           True          True    0.662831   \n",
       "194604         3          False          False         False    0.363010   \n",
       "\n",
       "        coherence  y  \n",
       "0        0.301004  1  \n",
       "1        0.000000  0  \n",
       "2        0.000000  0  \n",
       "3        0.123518  0  \n",
       "4        0.466869  0  \n",
       "...           ... ..  \n",
       "194600   0.000000  0  \n",
       "194601   0.663502  0  \n",
       "194602   0.606731  0  \n",
       "194603   1.000000  1  \n",
       "194604   0.348749  1  \n",
       "\n",
       "[194605 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "gbrt = GBRT(wiki2vec)\n",
    "for i in tqdm(range(1, 1163)):\n",
    "    data = pd.read_csv(f'./data/aida/candidates/{i}.csv')\n",
    "    data = data.dropna()\n",
    "    mentions = data['mention'].unique()\n",
    "    candidates = data['candidate'].unique()\n",
    "    max_prob = get_max_prior_prob(mentions, candidates)\n",
    "    \n",
    "    # Base features\n",
    "    data['priorProb'] = [get_prior_prob(i[1], i[2])\n",
    "                         for i in data[['candidate', 'mention']].itertuples()]\n",
    "    data['entityPrior'] = data['candidate'].map(get_entity_prior)\n",
    "    data['maxPriorProb'] = data['candidate'].map(max_prob)\n",
    "    data['numCands'] = [get_num_candidates(data, i[1], i[3])\n",
    "                        for i in data.itertuples()]\n",
    "    \n",
    "    # String similarity features\n",
    "    ment_normalised = data['mention'].map(lambda x: x.lower())\n",
    "    cand_normalised = data['candidate'].map(lambda x: x.lower().replace('_', ' '))\n",
    "    ment_cand = list(zip(ment_normalised, cand_normalised))\n",
    "    data['editDist'] = [get_edit_dist(m, c) for m, c in ment_cand]\n",
    "    data['mentionIsCand'] = [m == c for m, c in ment_cand]\n",
    "    data['mentionInCand'] = [m in c for m, c in ment_cand]\n",
    "    data['isStartorEnd'] = [c.startswith(m) or c.endswith(m) for m, c in ment_cand]\n",
    "\n",
    "    # Context based features\n",
    "    # Context similarity \n",
    "    context_emb = gbrt.encode_sentence(aida.get_document(i))\n",
    "    data['contextSim'] = data['candidate'].map(\n",
    "        lambda x: cos_sim(gbrt.encode_entity(x), context_emb))\n",
    "    # Coherence score\n",
    "    unamb_entities = data[data['priorProb'] >= 0.95]['candidate'].unique()\n",
    "    context_ent_emb = gbrt.encode_context_entities(unamb_entities)\n",
    "    data['coherence'] = data['candidate'].map(\n",
    "        lambda x: cos_sim(gbrt.encode_entity(x), context_ent_emb))\n",
    "    # Add rank\n",
    "    # data = rank_values(data)\n",
    "\n",
    "    # Add ground truth\n",
    "    data['y'] = (data['candidate'] == data['tag']).map(int)\n",
    "    dfs.append(data)\n",
    "\n",
    "X = pd.concat(dfs).replace('NIL', np.nan).dropna()\n",
    "X = X.reset_index(drop=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the GBRT Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, fname):\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.drop(columns=['mention', 'candidate', 'tag', 'y']).to_numpy()\n",
    "y_train = X['y'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0750          333.60m\n",
      "         2           0.0729          294.78m\n",
      "         3           0.0708          291.80m\n",
      "         4           0.0687          284.37m\n",
      "         5           0.0668          284.34m\n",
      "         6           0.0649          283.83m\n",
      "         7           0.0631          280.69m\n",
      "         8           0.0614          278.51m\n",
      "         9           0.0598          280.71m\n",
      "        10           0.0582          284.67m\n",
      "        20           0.0452          276.59m\n",
      "        30           0.0362          273.13m\n",
      "        40           0.0300          248.11m\n",
      "        50           0.0257          219.62m\n",
      "        60           0.0226          200.46m\n",
      "        70           0.0204          186.56m\n",
      "        80           0.0189          176.13m\n",
      "        90           0.0177          168.23m\n",
      "       100           0.0168          161.73m\n",
      "       200           0.0139          131.59m\n",
      "       300           0.0131          122.58m\n",
      "       400           0.0126          118.48m\n",
      "       500           0.0123          115.73m\n",
      "       600           0.0120          113.88m\n",
      "       700           0.0117          112.48m\n",
      "       800           0.0114          118.09m\n",
      "       900           0.0112          119.48m\n",
      "      1000           0.0110          120.60m\n",
      "      2000           0.0095          123.22m\n",
      "      3000           0.0086          109.61m\n",
      "      4000           0.0078           99.90m\n",
      "      5000           0.0072           91.85m\n",
      "      6000           0.0066           84.55m\n",
      "      7000           0.0061           77.71m\n",
      "      8000           0.0057           70.87m\n",
      "      9000           0.0054           63.89m\n",
      "     10000           0.0051           57.24m\n",
      "     20000           0.0031            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.02, max_depth=4, n_estimators=20000,\n",
       "                          random_state=0, verbose=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(n_estimators=20000, learning_rate=0.02,\n",
    "                                  max_depth=4, random_state=0, verbose=True)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, './data/GBRT/coherence20.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GBRT(wiki2vec, model_path='coherence20.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231/231 [11:43<00:00,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get all mentions and their tags\n",
    "doc = 1162\n",
    "mentions_tags = {i:[] for i in range(1163, 1394)}\n",
    "for i in aida.aida_sets['test']:\n",
    "    context = i.to_plain_string()\n",
    "    if context != '-DOCSTART-':\n",
    "        mentions_tags[doc].extend([[j.text, j.tag] for j in i.get_spans()])\n",
    "    else:\n",
    "        doc += 1\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "all_preds = []\n",
    "for i in tqdm(range(1163, 1394)):\n",
    "    mentions_cands = [[mention, aida.get_candidates(i, mention, tag)]\n",
    "                      for mention, tag in mentions_tags[i]]\n",
    "    predictions = gbrt.link(mentions_cands, aida.get_document(i))\n",
    "    for j, (mention, tag) in enumerate(mentions_tags[i]):\n",
    "        m, pred, conf = predictions[j]\n",
    "        assert m == mention\n",
    "        all_preds.append([m, tag, pred])\n",
    "        total += 1\n",
    "        if pred == tag:\n",
    "            correct += 1\n",
    "\n",
    "print(\"Accuracy:\", round((correct/total)*100, 3))\n",
    "\n",
    "res = pd.DataFrame(all_preds, columns=['mention', 'tag', 'pred'])\n",
    "res.to_csv('./results/gbrt_coherence.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "|CoNLL (PPRforNED)|Accuracy|Excepted|\n",
    "|----|----|----|\n",
    "|Base|81.921|85.4|\n",
    "|+ String similarity|82.944|85.8|\n",
    "|+ Textual context|86.035|90.9|\n",
    "|+ Coherence|88.326, 88.526|91.4|\n",
    "|Two-step|88.192|93.1|"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3c83394ae731fac5cbf34b5abe7ebcd59fb96b846f104eed2689aeb9dd8ae81"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('NED-using-KG': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
