{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GBRT data files...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.base import Base, BaseWiki2Vec\n",
    "from src.GBRT import GBRT\n",
    "from src.utils import test_local, test_global\n",
    "\n",
    "EMB_PATH = \"C:\\\\Personal Files\\\\NED-using-KG\\\\embeddings\\\\\"\n",
    "WIKI2VEC = EMB_PATH + 'wiki2vec_w10_100d.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_results = []\n",
    "embs = ['word2vec-google-news-300', 'glove-wiki-gigaword-300',\n",
    "        'fasttext-wiki-news-subwords-300', 'en.wiki.bpe.vs200000.d300.w2v']\n",
    "\n",
    "for emb in embs:\n",
    "    res = [emb]\n",
    "    model = Base(EMB_PATH + emb)\n",
    "    for case in [True, False]:\n",
    "        model.cased = case\n",
    "        acc, _ = test_local(model)\n",
    "        res.append(acc)\n",
    "    base_results.append(res)\n",
    "\n",
    "acc, _ = test_local(BaseWiki2Vec(WIKI2VEC))\n",
    "base_results.append(['wiki2vec_w10_100d', acc, acc])\n",
    "\n",
    "res = pd.DataFrame(base_results, columns=['Embedding', 'Accuracy (cased)', 'Accuracy (uncased)'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test GBRT (and it's variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231/231 [15:02<00:00,  3.91s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "pretrained = ['base.pkl', 'string_sim.pkl', 'context.pkl', 'coherence_no_rank.pkl']\n",
    "for i in pretrained[:1]:\n",
    "    model = GBRT(WIKI2VEC, model_path=i)\n",
    "    acc, res = test_global(model)\n",
    "    results.append([i[:-3], acc, res.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GBRT(WIKI2VEC, model_path=i)\n",
    "model.two_step = True\n",
    "acc, res = test_global(model)\n",
    "print(f\"{i} {acc} {res.shape[0]}\")  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3c83394ae731fac5cbf34b5abe7ebcd59fb96b846f104eed2689aeb9dd8ae81"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('NED-using-KG': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
